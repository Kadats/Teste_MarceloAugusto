# üè• Monitor de Despesas - Dados Abertos ANS

> Teste T√©cnico para Engenharia de Dados / Full Stack - Intuitive Care

Este projeto √© uma solu√ß√£o completa (End-to-End) para coleta, processamento, an√°lise e visualiza√ß√£o das despesas de Operadoras de Planos de Sa√∫de, utilizando dados p√∫blicos da Ag√™ncia Nacional de Sa√∫de Suplementar (ANS).

---

## üöÄ Tecnologias Utilizadas

### Backend & Engenharia de Dados
* **Linguagem:** Python 3.12
* **Framework API:** FastAPI (Alta performance e documenta√ß√£o autom√°tica)
* **Banco de Dados:** PostgreSQL
* **ETL & An√°lise:** Pandas, SQLAlchemy, BeautifulSoup4
* **Infraestrutura:** Docker & Docker Compose

### Frontend
* **Framework:** Vue.js 3 (Composition API)
* **Build Tool:** Vite
* **Visualiza√ß√£o:** Chart.js (Vue-Chartjs)
* **Cliente HTTP:** Axios

---

## üõ†Ô∏è Como Executar o Projeto

A maneira recomendada de executar a aplica√ß√£o √© utilizando **Docker**, garantindo que todo o ambiente (Banco, API e Interface) suba com um √∫nico comando, isolado do seu sistema operacional.

### Passo 1: Subir o Ambiente
No terminal, na raiz do projeto, execute:

```bash
docker compose up --build -d
```
*Aguarde alguns instantes para o build dos containers e inicializa√ß√£o do banco.*

### Passo 2: Popular o Banco de Dados (Pipeline ETL)
Como o banco de dados inicia vazio, √© necess√°rio rodar o orquestrador para baixar e processar os dados da ANS:

```bash
docker compose exec backend python main.py
```
*O sistema far√° o download dos arquivos, corre√ß√£o de encoding, transforma√ß√£o e carga no PostgreSQL. Aguarde a mensagem "SUCESSO".*

### Passo 3: Acessar a Aplica√ß√£o
* **Dashboard:** [http://localhost:5173](http://localhost:5173)
* **API Docs:** [http://localhost:8000/docs](http://localhost:8000/docs)


---

## üèóÔ∏è Arquitetura e Decis√µes T√©cnicas (Trade-offs)
Para cumprir o prazo de 7 dias com m√°xima efici√™ncia e qualidade, as seguintes decis√µes arquiteturais foram tomadas:

### 1. Estrat√©gia de Coleta (Scraper)
* **BeautifulSoup vs Selenium:** Optei pelo `BeautifulSoup` + `requests`. Como o diret√≥rio FTP da ANS √© est√°tico, o uso de Selenium seria um desperd√≠cio de recursos (overhead de mem√≥ria). A solu√ß√£o atual √© leve e extremamente r√°pida.

* **Armazenamento em Disco:** Os arquivos `.zip` s√£o baixados para a pasta `/data` antes do processamento. Isso cria um checkpoint de seguran√ßa, evitando re-downloads em caso de falha no processamento, al√©m de proteger a mem√≥ria RAM contra estouros ao lidar com arquivos grandes.

### 2. Tratamento de Encoding (Desafio & Solu√ß√£o)
* **O Problema:** Identifiquei que os arquivos CSV da ANS utilizam codifica√ß√£o antiga (**ISO-8859-1/Latin-1**), enquanto o ambiente Python/Linux moderno opera em **UTF-8**. Isso causava erros de "mojibake" (ex: "M√âDICA" virava "M√ÉDICA").

* **A Solu√ß√£o:** Implementei uma leitura resiliente ("Fallback Strategy") no pipeline. O sistema tenta ler em **UTF-8**; se falhar, reprocessa automaticamente for√ßando Latin-1. Isso garante a integridade dos nomes das operadoras no Dashboard final.

### 3. API e Backend
* **FastAPI vs Flask:** Escolhi FastAPI pela valida√ß√£o nativa de dados (Pydantic), performance ass√≠ncrona (ASGI) e gera√ß√£o autom√°tica do Swagger, acelerando o desenvolvimento e a documenta√ß√£o.

* **Pagina√ß√£o:** Implementada via `Limit/Offset`. Para o volume atual de dados (~700 operadoras ativas), essa abordagem √© simples e eficiente, evitando complexidade desnecess√°ria no Frontend.

### 4. Interface Web (Frontend)
* **Vue.js 3:** Escolhido pela reatividade e performance.

* **Chart.js:** Utilizado para renderizar o gr√°fico das "Top 10 Despesas", oferecendo uma visualiza√ß√£o clara para tomada de decis√£o executiva.

---

## üîÆ Melhorias Futuras (Next Steps)
Dado mais tempo para evolu√ß√£o do produto, os pr√≥ximos passos seriam:

**1. Testes Automatizados:** Implementa√ß√£o de `pytest` para cobrir as regras de neg√≥cio do ETL (c√°lculo de m√©dia e desvio padr√£o) e Mocks para testar o Scraper sem depender da disponibilidade do site da ANS.

**2. Orquestra√ß√£o Profissional:** Migra√ß√£o do script `main.py` para Apache Airflow ou Prefect, permitindo agendamento di√°rio e monitoramento visual de falhas no pipeline.

**3. CI/CD:** Configura√ß√£o de GitHub Actions para linting e testes a cada Push.

---

## üë®‚Äçüíª Autor
### Marcelo Augusto